# Chatbot Assistant Scolaire - College Francais

## Objectif
Chatbot RAG qui repond **uniquement** a partir de cours et programmes scolaires du college francais (6eme-3eme). Le bot refuse de repondre si l'information n'existe pas dans la base de donnees.

## Current Project State
| Aspect | Status |
|--------|--------|
| Scraper Vikidia | âœ… TERMINE - 8 matieres scrapees (24 321 articles, 43 857 chunks) |
| Scraper Wikiversite | âŒ ABANDONNE - 0.4% pages exploitables (507 pages testees, 2 lessons) |
| Scraper Academie en Ligne | âŒ ABANDONNE - URLs obsoletes (8 pages irrelevantes) |
| ChromaDB ingestion | âœ… TERMINE - 43 870 documents ingeres dans 'cours_college' |
| Backend FastAPI | âœ… PRODUCTION-READY - RAG + Auto-dÃ©tection + BibliothÃ¨que (limite 50k leÃ§ons) |
| Backend Auto-DÃ©tection | âœ… TERMINE - DÃ©tection niveau/matiÃ¨re par mots-clÃ©s |
| Backend BibliothÃ¨que | âœ… TERMINE - 3 endpoints (chat/auto, lecons, detail) |
| Frontend SPA | âœ… PRODUCTION-READY - 4 vues (Chat, BibliothÃ¨que, Favoris, DÃ©tail) |
| Frontend Chat | âœ… TERMINE - Auto-dÃ©tection + choix ambiguÃ¯tÃ© + history persistant |
| Frontend BibliothÃ¨que | âœ… TERMINE - Pagination (50/fois) + Recherche full-text + Cache intelligent |
| Frontend Favoris | âœ… TERMINE - SystÃ¨me complet avec localStorage + animations |
| Frontend Mode Sombre | âœ… TERMINE - Toggle dark/light avec localStorage + auto-detect OS |
| Frontend Optimisations | âœ… TERMINE - Pagination, animations optimisÃ©es, cartes cliquables |
| Tests | â³ Non implementes (backend teste manuellement) |
| Deployment | â³ Local uniquement (port 8000) |
| Git status | âœ… Clean - Dernier commit: a42a184 (search + pagination + favorites) |

## Last Session Summary (2026-02-07 - Session 4)
**RECHERCHE + PAGINATION + FAVORIS - BibliothÃ¨que complÃ¨te**

**Phase 1 : Suppression limite backend** :
1. âœ… `backend/rag.py` - Limite passÃ©e de 100 Ã  50 000 leÃ§ons
2. âœ… `backend/main.py` - Limite endpoint passÃ©e de 100 Ã  50 000
3. âœ… Toutes les leÃ§ons accessibles dans la bibliothÃ¨que

**Phase 2 : Pagination intelligente** :
1. âœ… Chargement progressif : 50 leÃ§ons Ã  la fois
2. âœ… Bouton "Charger 50 leÃ§ons de plus" avec compteur
3. âœ… Animations optimisÃ©es (dÃ©lai max 1.5s au lieu de 5s)
4. âœ… Reset pagination lors changement de matiÃ¨re
5. âœ… Performance : 13k+ leÃ§ons gÃ©rÃ©es sans ralentissement

**Phase 3 : Recherche full-text** :
1. âœ… Barre de recherche en temps rÃ©el dans bibliothÃ¨que
2. âœ… Recherche insensible aux accents (`normalizeString()`)
3. âœ… Recherche insensible Ã  la casse
4. âœ… Filtre par titre ET rÃ©sumÃ©/contenu
5. âœ… Bouton "âœ•" pour effacer la recherche
6. âœ… Message "Aucun rÃ©sultat" avec suggestions
7. âœ… Compteur de rÃ©sultats dynamique

**Phase 4 : SystÃ¨me de favoris** :
1. âœ… Bouton Ã©toile â˜†/â­ sur chaque carte de leÃ§on
2. âœ… Toggle favori avec animation (rotation + pulse)
3. âœ… localStorage pour persistence (survit au refresh)
4. âœ… Nouvelle vue "â­ Favoris" dans navigation
5. âœ… Tri par date d'ajout (plus rÃ©cents en premier)
6. âœ… Ã‰tat vide stylisÃ© avec icÃ´ne animÃ©e et CTA
7. âœ… Bordure colorÃ©e sur cartes favorites
8. âœ… Fonctions: `loadFavorites()`, `saveFavorites()`, `isFavorite()`, `toggleFavorite()`

**Fichiers modifiÃ©s** :
- `backend/rag.py` : +2 lignes (limite 50k)
- `backend/main.py` : +1 ligne (limite 50k)
- `frontend/app.js` : +250 lignes (recherche, pagination, favoris)
- `frontend/index.html` : +3 lignes (bouton Favoris nav)
- `frontend/style.css` : +120 lignes (styles recherche, favoris, animations)

**Commits crÃ©Ã©s** :
- `a42a184` - Add search, pagination, and favorites features
- `92c8376` - Merge feature/dark-mode into main
- `2a2d4f5` - Fix library animations and improve lesson content formatting

**RÃ©sultat** : BibliothÃ¨que optimisÃ©e, searchable, avec favoris persistants

## Next Immediate Action

**Option 1 : Continuer les amÃ©liorations UX**

Prochaines features recommandÃ©es (voir `docs/PLAN_AMELIORATIONS.md`) :
1. ğŸ§ª **Tests automatisÃ©s** (14h) - pytest backend + playwright frontend
2. ğŸ“ **Classification par niveau** (8h) - Script dÃ©jÃ  prÃªt (`backend/classify_levels.py`)
3. ğŸ“Š **Statistiques utilisateur** (4h) - Tracker recherches, favoris, temps
4. ğŸ”” **Notifications** (3h) - Toast messages pour actions (favori ajoutÃ©, etc.)

**Option 2 : DÃ©ploiement**

DÃ©ployer sur Render/Railway :
1. CrÃ©er `requirements.txt` complet
2. CrÃ©er `Procfile` pour backend
3. Configurer variables d'environnement
4. Setup ChromaDB persistence cloud

**Option 3 : Features avancÃ©es**

1. ğŸ“ **Export PDF** - GÃ©nÃ©rer PDF des leÃ§ons
2. ğŸ¤ **Voice input** - DictÃ©e vocale pour questions
3. ğŸŒ **i18n** - Support multi-langues
4. ğŸ“± **PWA** - Application installable

**Commandes pour lancer l'app** :

```bash
cd C:\Users\skwar\Desktop\RAG

# Lancer le backend (dans un terminal)
cd backend
uvicorn main:app --reload --port 8000

# Ouvrir dans le navigateur
# http://localhost:8000

# Tester les nouvelles features :
# 1. Cliquer sur "ğŸ“š BibliothÃ¨que" puis une matiÃ¨re (ex: Histoire-GÃ©o)
# 2. Utiliser la barre de recherche ğŸ” (ex: "rÃ©volution")
# 3. Cliquer sur "Charger 50 leÃ§ons de plus" pour pagination
# 4. Cliquer sur â­ pour ajouter aux favoris
# 5. Cliquer sur "â­ Favoris" dans la navigation
# 6. Tester le mode sombre ğŸŒ™
```

## Stack technique
- **Backend** : Python 3.11+ / FastAPI / LangChain
- **Vector DB** : ChromaDB (persistance locale dans `chromadb/`)
- **LLM** : OpenAI GPT-4o-mini
- **Embeddings** : OpenAI text-embedding-3-small
- **Frontend** : HTML / CSS / JS vanilla
- **Scraping** : cloudscraper + BeautifulSoup + API MediaWiki (Cloudflare bypass)

## Structure du projet
```
RAG/
â”œâ”€â”€ scraper/        # Collecte et traitement des donnees scolaires
â”‚   â”œâ”€â”€ vikidia.py      # Scraper Vikidia (API MediaWiki + cloudscraper)
â”‚   â”œâ”€â”€ cleaner.py      # Nettoyage texte (LaTeX, HTML, sections inutiles)
â”‚   â”œâ”€â”€ chunker.py      # Decoupage en chunks ~500 tokens avec overlap
â”‚   â”œâ”€â”€ metadata.py     # Categories, matieres, niveaux
â”‚   â””â”€â”€ pipeline.py     # Orchestration scrape -> clean -> chunk -> save
â”œâ”€â”€ backend/        # API FastAPI + chaine RAG LangChain
â”‚   â”œâ”€â”€ main.py         # Endpoints API (chat, lecons, detail)
â”‚   â”œâ”€â”€ rag.py          # ChaÃ®ne RAG (retrieve + generate)
â”‚   â”œâ”€â”€ prompts.py      # Prompts adaptÃ©s par niveau
â”‚   â”œâ”€â”€ detection.py    # Auto-dÃ©tection niveau/matiÃ¨re
â”‚   â””â”€â”€ ingest_chromadb.py  # Script ingestion
â”œâ”€â”€ frontend/       # Interface SPA HTML/CSS/JS
â”‚   â”œâ”€â”€ index.html      # Structure + navigation
â”‚   â”œâ”€â”€ app.js          # Router SPA + 4 vues + favoris
â”‚   â””â”€â”€ style.css       # Design system "Cahier NumÃ©rique"
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/vikidia/    # Articles bruts par matiere (JSON)
â”‚   â””â”€â”€ processed/      # Chunks prets pour embedding (JSON)
â”œâ”€â”€ chromadb/       # Base vectorielle ChromaDB (persistee)
â”œâ”€â”€ docs/           # Documentation et plans
â”œâ”€â”€ .env            # Cles API (NE PAS COMMITTER)
â””â”€â”€ requirements.txt
```

## Sources de donnees
- **Vikidia** : articles encyclopediques adaptes aux collegiens (API MediaWiki) - âœ… UTILISE (43 857 chunks)
- **Wikiversite** : cours structures niveau college (API MediaWiki) - âŒ ABANDONNE (99.6% pages vides)
- **Academie en Ligne (CNED)** : cours par niveau - âŒ ABANDONNE (site restructure, URLs obsoletes)

## Matieres
| Matiere | Source Vikidia | Articles | Chunks |
|---------|---------------|----------|--------|
| Histoire-Geo | Categories:Histoire,Geographie | 13 112 | 25 474 |
| SVT | Categories:Biologie,Geologie | 5 454 | 8 481 |
| Francais | Categories:Francais,Grammaire,Litterature | 3 040 | 4 835 |
| Physique-Chimie | Categories:Physique,Chimie | 1 439 | 2 751 |
| Technologie | Categories:Technologie | 724 | 1 349 |
| Mathematiques | Categories:Mathematiques | 543 | 967 |
| Anglais | Categories:Anglais | 6 | - |
| Espagnol | Categories:Espagnol | 3 | - |
| **TOTAL** | | **24 321** | **43 857** |

## Features principales

### ğŸ’¬ Chat intelligent
- Auto-dÃ©tection niveau et matiÃ¨re par mots-clÃ©s
- Gestion des questions ambiguÃ«s (choix manuel)
- Historique de conversation persistant
- Badge de dÃ©tection visible
- Prompts adaptÃ©s par niveau (6Ã¨me, 5Ã¨me, 4Ã¨me, 3Ã¨me)

### ğŸ“š BibliothÃ¨que
- 43 870 leÃ§ons Vikidia organisÃ©es par matiÃ¨re
- **Pagination intelligente** : 50 leÃ§ons/page, chargement progressif
- **Recherche full-text** : temps rÃ©el, insensible accents/casse
- Cartes de leÃ§ons cliquables (titre, rÃ©sumÃ©, mÃ©tadonnÃ©es)
- Navigation : BibliothÃ¨que â†’ MatiÃ¨re â†’ LeÃ§on â†’ DÃ©tail
- Cache intelligent (pas de re-fetch)

### â­ Favoris
- Bouton Ã©toile sur chaque leÃ§on
- Stockage localStorage (persistant)
- Vue dÃ©diÃ©e "Mes Favoris"
- Tri par date d'ajout
- Animations fluides (pulse, rotation)

### ğŸŒ™ Mode sombre
- Toggle light/dark avec bouton ğŸŒ™/â˜€ï¸
- 30+ variables CSS pour cohÃ©rence
- Auto-dÃ©tection prÃ©fÃ©rence OS
- Persistance localStorage
- Transitions fluides

### ğŸ¨ Design "Cahier NumÃ©rique"
- Background papier avec grille 8x8px
- Typography: Lexend (headings) + DM Sans (body)
- 8 couleurs par matiÃ¨re
- Animations CSS fluides
- Responsive mobile-first

## Contraintes critiques
1. **Reponse uniquement depuis la base** : le LLM ne doit JAMAIS utiliser ses connaissances propres
2. **Filtrage niveau/matiere** : chaque chunk est tague avec metadonnees
3. **Refus hors-perimetre** : si aucun chunk pertinent trouve, le bot dit qu'il ne sait pas
4. **Pas de secrets dans le code** : utiliser `.env` pour les cles API

## Commandes utiles
```bash
# Installer les dependances
pip install -r requirements.txt

# Lancer le backend
cd backend
uvicorn main:app --reload --port 8000

# Ouvrir l'app
# http://localhost:8000

# Lancer le scraping (toutes matieres)
python -m scraper.pipeline

# Lancer le scraping (une matiere)
python -m scraper.pipeline --matiere mathematiques

# Ingestion ChromaDB
cd backend
python ingest_chromadb.py
```
